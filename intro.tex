% !TEX root = icmlsoft.tex

\section{Introduction}

% Outline: Conditioning is a general mechanism for expressing declarative knowledge, but so far it has been limited

In Bayesian inference, conditioning is the mechanism by observed data is incorporated into a model.
In a broader sense, conditioning is the mechanism to assert facts we know to be true without specifying the means by which they are true.
For instance, the expression $p(\theta \mid X = x)$ asserts that the predicate $X = x$ must hold, but does not specify how.

Many useful predicates assert something other than the observation of data.
For example, in inverse graphics \cite{} -- inferring three dimensional geometry that caused an observed image -- statements such as ``rigid bodies do not intersect'' are not observational but easily expressed as predicates.
Incorporating true statements (i.e., facts) into a model shifts it closer to reality, ultimately increasing the probability of the true cause under the model.
In cases where such facts are not easily incorporated into the model constructively (e.g., it is challenging to define a prior over geometry that satisfies non-intersection), they can in principle simply be conditioned on.
% In fact, this example restricts latent variables (geometry), muddling the prior-posterior dichotomy.
% In medical applications such as modeling the glucose dynamics ~\citep{levine2017offline}, a practitioner may know that ``human glucose curves are similar across patients''.	
% A scientist could define a generative model that captures prior knowledge of how glucose levels evolve over time -- for example, the model may use latent variables to identify when a person eats and the glycemic loads a person consumes, and encode physiological knowledge of how those meals will affect glucose levels.
% The scientist could also condition the model on observations of glucose measurements of a given patient and use existing inference algorithms to sample from the posterior distributions over latent variables.
% However, there are various pieces of declarative knowledge the scientist may possess which are difficult or impossible to encode in this form.
% For instance, she may know that ``human glucose curves are similar across patients'',   is surprisingly challenging even in the most expressive probabilistic programming systems. 
% Rather than observations, these propositions are facts which condition the prior. These propositions are not observations.


% WTP: What are simulation based models, what is bayesian inference in them.  Why is it necessary. 
% Inference on models conditioned on more general predicates yield challenging inference problems, especially when the models are represented as stochastic simulators.
% For many phenomena in the world, we can build models that 
% attempt to simulate how they evolve. One purpose of 
% these models is to draw samples from unobserved variables 
% conditional on the output of the simulation, i.e, perform
% posterior inference.
% Most algorithms which draw samples from posterior distributions rely on
% the likelihood function, which quantifies the extent to which values of 
% unobserved variables are consistent with observations.
% Simulation models, however leave the likelihood functions implicit
% and difficult to derive.
% %This can occur, for example, when non-latent variables are unobserved, since they must be margainalized out, or when transformed densities are conditioned.
% Simulation based models can apply arbitrary, non-injective transformations to their input, and hence induce intractable likelihoods for any or all of these reasons.

% A less explored cause of intractability is propositions that are not observations in the conventional sense.
% To observe data $x$ as the output of a simulation model $X$ means to condition the model on the proposition $X = x$.
% There are several propositions that do not conform to this structure, which we would nevertheless like to condition our models on.
% These propositions may impose constraints on latent variables, or even jointly on latent and observations.
% For example.
% They could also be observational but more abstract than concrete data.
% For example,.
% All such statements can be enforced through conditioning, but generally the resulting likelihood will be intractable or may not exist,


% Problems of inference, on the other hand, are typically anti-causal: having observed the result of the simulation we wish to infer the causes.



% lack succinct equations governing their behavior but nevertheless understand the causal mechanisms by which they evolve.
% Such phenomena can be simulated, which means to execute a program and associate states which arise in its execution with entities in the domain.
% as an algorithm which solves the equations which govern it. Values, states, and transitions in the execution of the algorithm correspond to entities in the domain.
% This execution generally follows the causal direction of the domain in the sense that if $a$ causes $b$, $b$ is computed from $a$ in simulation.
% Problems of inference, on the other hand, are typically anti-causal: having observed the result of the simulation we wish to infer the causes.



% WTP: What are likelihood functions, why are they use useful, and why are they intractable
% The Bayesian approach to inference is to first quantify all uncertainty with probability distributions, and as a result uniquely specify the posterior distribution given observed values.
% % Bayesian inference is a principled framework for inferring probable causes of observed values, but relies on terms which are often intractable.
% Most algorithms which draw samples from posterior distributions rely on
% % Bayes theorem dictates that the posterior distribution over latent variables given observations is is proportional to the product of the likelihood function and prior.
% the likelihood function, which quantifies the extent to which values of latent variables are consistent with observations.
% Simulation models explicitly represent the processes which generate data, but leave the likelihood functions implicit. 
% The likelihood  difficult to derive from a simulation model and is often intractable to evaluate.
% This can occur, for example, when non-latent variables are unobserved, since they must be margainalized out, or when transformed densities are conditioned.
% Simulation based models can apply arbitrary, non-injective transformations to their input, and hence induce intractable likelihoods for any or all of these reasons.

% Morever, approximate inference algorithm 

% % A less explored cause of intractability occurs when we condition on propositions that are not observations of data.
% For example, if $X$ and $Y$ are normally distributed random variables, then conditioning on $X = Y$ does not permit a density function, let alone a tractable one.
% Conditioning on inequalities such $X > 4$, transformations such $X^2  = 0$, and logical formulas such as  $X = 3 \lor X = 5$ falls outside the domain of virtually all conditional sampling algorithms.
% % As a consequence, conditioning in practice is significantly more limited than its theoretical counterpart.

% The value of probabilistic programming systems hinges on how easily a practitioner can encode domain knowledge into a model. Existing probabilistic programming systems support two main mechanisms for encoding knowledge: implicitly in the generative model, and explicitly by conditioning on observations. There are many contexts, however, for which neither of these two mechanisms are sufficient to encode the knowledge that practitioners have about a process.

% WTP: Implications of the Problem


% WTP: Non-obvious benefits of solving the problem:  Prior conditioning.
% Declarative knowledge has the potential to serve as the bridge between classical parametric models, and recent trend towards nonparameric or highly parameterized families such as deep neural networks.
% For example, inverse graphics attempts to infer the three dimensional scene (geometry, lights, camera, etc) which caused an observed image.
% A Bayesian formulation of the problem requires a prior distributions over scenes.
% Simple parametric stand little chance of capturing the complexity of real world scenes.

% Outline: Non-observational predicates induce intractable likelihoods
% and are largely unsupported by current methods of inference
Conditioning on a predicates belonging to a broader class presents severe inference challenges.
Several sampling  \citep{andrieu2003introduction} and variational  \citep{jordan1999introduction, ranganath2014black} approaches to inference require only the likelihood function -- which quantifies the extent to which values of latent variables are consistent with observations -- as a black-box that can be evaluated.
However, non-observational predicates tend to induce likelihood functions that are difficult to derive, intractable to compute, or inadmissible.
For example, if a	predicate often restrict variables that do not explicitly appear in the data generating process.
For example, given three variables, it is possible to condition on the sum
of the variables being positive; this sum is never an explicit random variable.
Rather than use the likelihood as a black-box, the predicate itself.  Unfortunately,predicates return only limited information: 1 when satisfied and 0 otherwise.
This curtails the potential of any inference strategy that uses predicates as black-boxes.

In this paper, we present an inference approach which extracts more information from predicates through a syntactically transformation of the model, yielding relaxed predicates which takes values in the unit interval $[0, 1]$. The extremes $0$ and $1$ are consistent with the original predicate, but intermediate values denote the graded degree to which the predicate is satisfied.

Graded predicates derive their meaning from distance metrics.
For example, a predicate of the form $X = Y$ may be substituted with a softened counter-part of the form $k(d(X, Y))$ where $k$ is some kernel ensuring.
While distance functions are commonplace in Approximate Bayesian Computation (ABC) approaches to likelihood-free inference, we target exact inference.
Relaxations are modulated by a temperature parameter $\alpha$ such that at zero temperature the relaxed predicate mirrors its hard counter-part, while at maximal temperatures virtually everything will satisfy the constraint.
In a form of parallel-tempering, we simulate a number Markov chain in paralle.

Knowledge often has a Boolean structure.
We may know that a statement is not true, that two statements simultaneously hold, that at least one of them holds or at most one of them holds.
Such structure is captured naturally by a Boolean algebra over predicates, but neither likelihood-based inference nor existing likelihood-free inference offer effective means to condition non-trivial models on such compound primitive.
A second component of this contribution is a complete set of softened Boolean primitives that compose arbitrarily while retaining consistency with unrelaxed counterpart.

Conditioning on predicates introduces problems of zero-measure, which are often side-stepped in likelihood-based inference.
In particular, in practice our algorithm is applicable to predicates of non-zero measure.
% zero. However, mixing may be slow since condition on general predicates
% encodes the class of decision problems.
For measure zero predicates -- typically from equalities such as $X = Y$ in continuous models -- our algorithm produces samples at a temperature strictly greater than zero to ensure a non-zero exchange probability.
This samples are approximate.
% Hard valued predicates do not have scaling issues as they are either zero or one valued, but soft valued predicates can have issues. Our procedure
% to convert from hard valued predicates to soft valued ones
% tries to ensure that each predicate gets satisfied with equal
% probability at a fixed temperature. This equal weighting 
% avoids bias for one predicate or another due to the choice of sampling.

% We build our inference algorithm into a system.
% \emph{Omega} provides an to define a generative model and declare
% predicates about it. Given these definitions, \emph{Omega} automatically
% performs inference using our soften-contraint replica exchange algorithm.
% We test \emph{Omega} on a simulated example with truncated Gaussians,
% an object rendering model, a physiological model, and xxx 

In summary we address the problem of conditioning on broad class of predicates as am class to express declarative knowledge.
In detail, we:

\begin{enumerate}
	\item Formalize (section \ref{}) simulation based models in terms of measure theoretic probability, and conditioning as the imposition of constraints.
	\item Present a syntactic transformation to probabilistic model that transforms predicates into relaxted counterparts. 
	\item Present an algorithm based on replica-exchange Markov Chain Monte Carlo (section \ref{}) which draws exact samples for positive measure predicates. 
	\item Implement these concepts in system for building models, predicates, and doing inference.
	\item Evaluate our approach on representative examples, and demonstrate case studies including enriching medical models with limited data.
\end{enumerate}


% WTP: Contribution: inference algorithm that supports conditioning on a wider class of propositions
% In this paper we present an algorithm that draws samples from generative models that have been conditioned on predicates belonging to a more general class than observation of data.
% Predicates, when used as black boxes, provide only sparse information -- the constraint is satisfied or it is not -- and the subset of satisfying constraints is typically vanishingly small.
% Our objective is to support conditioning on predicates on spaces for which a natural metric can be defined.
% A metric provides more information a measure of the degree of satisfaction, and allows us.

% WTP: Paper summary
% In summary we address the problem of conditioning on declarative knowledge.
% In more detail:
% \begin{itemize}
% \item We formalize simulation models in measure-theoretic probability as random variables defined on a shared probability space (section X), and define conditioning as a concentration of measure.
% \item We describe our approach to inference, which softens the hard constraints to admit tractable inference in a broader set of scenarios.
% \item  We demonstrate our approach on a number of examples, with experiments on toy data and experiments on medical models by enriching them with declarative knowledge to learn from limited data.
% \end{itemize}