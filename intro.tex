% !TEX root = icmlsoft.tex

\section{Introduction}

Conditioning in Bayesian inference incorporates observed data into a model.
In a broader sense, conditioning is a mechanism to revise a model such that a yes/no question (a predicate) becomes a true proposition (a fact).
For instance, the question of whether a variable is equal to a particular value, changes from a predicate of uncertain truth to a true fact once it is observed.
In principle, a predicate can be used to declare any proposition about a domain, not only the observation of data.
In practice, sampling from models conditioned on most predicates presents severe challenges to existing inference procedures.

Predicates can be used to update a model to adhere to known facts about a domain, without the burden of specifying how.
For example, in inverse graphics \cite{kulkarni2015deep} (inferring three dimensional geometry from observed images) the proposition ``rigid bodies do not intersect'' is a predicate on latent configurations of geometry.
To manually revise a model to constructively adhere to this fact is often infeasible.
Instead, we would ideally simply condition on it being true, concentrating probability mass on a subset of the latent variable space, and ultimately yielding more accurate posterior inferences in the inverse graphics problem.

Predicates can also express observations that are more abstract than variables in a model.
In diabetes research for example, probabilistic models have been used to relate physiological factors to glucose levels over time \citep{levine2017offline,murata2004probabilistic}.
Rather than concrete, numerical glucose measurements, a medical practitioner may observe (or be told) that a patient suffers from recurrent hypoglycemia, i.e., that their glucose levels periodically fall below a critical value.
Even if the occurrence of hypoglycemia does not appear as an explicit variable in the model, it could be constructed as a predicate on glucose levels, and conditioned on to infer the posterior distribution over latent physiological factors.


% ``glucose curves are similar across patients''.	

% It is difficult to define priors of latent geometry that satisfies non-intersection constructively.
% A scientist could define a generative model that captures prior knowledge of how glucose levels evolve over time -- for example, the model may use latent variables to identify when a person eats and the glycemic loads a person consumes, and encode physiological knowledge of how those meals will affect glucose levels.
% The scientist could also condition the model on observations of glucose measurements of a given patient and use existing inference algorithms to sample from the posterior distributions over latent variables.
% However, there are various pieces of declarative knowledge the scientist may possess which are difficult or impossible to encode in this form.
% For instance, she may know that ``human glucose curves are similar across patients'',   is surprisingly challenging even in the most expressive probabilistic programming systems. 
% Rather than observations, these propositions are facts which condition the prior. These propositions are not observations.


% WTP: What are simulation based models, what is bayesian inference in them.  Why is it necessary. 
% Inference on models conditioned on more general predicates yield challenging inference problems, especially when the models are represented as stochastic simulators.
% For many phenomena in the world, we can build models that 
% attempt to simulate how they evolve. One purpose of 
% these models is to draw samples from unobserved variables 
% conditional on the output of the simulation, i.e, perform
% posterior inference.
% Most algorithms which draw samples from posterior distributions rely on
% the likelihood function, which quantifies the extent to which values of 
% unobserved variables are consistent with observations.
% Simulation models, however leave the likelihood functions implicit
% and difficult to derive.
% %This can occur, for example, when non-latent variables are unobserved, since they must be margainalized out, or when transformed densities are conditioned.
% Simulation based models can apply arbitrary, non-injective transformations to their input, and hence induce intractable likelihoods for any or all of these reasons.

% A less explored cause of intractability is propositions that are not observations in the conventional sense.
% To observe data $x$ as the output of a simulation model $X$ means to condition the model on the proposition $X = x$.
% There are several propositions that do not conform to this structure, which we would nevertheless like to condition our models on.
% These propositions may impose constraints on latent variables, or even jointly on latent and observations.
% For example.
% They could also be observational but more abstract than concrete data.
% For example,.
% All such statements can be enforced through conditioning, but generally the resulting likelihood will be intractable or may not exist,


% Problems of inference, on the other hand, are typically anti-causal: having observed the result of the simulation we wish to infer the causes.



% lack succinct equations governing their behavior but nevertheless understand the causal mechanisms by which they evolve.
% Such phenomena can be simulated, which means to execute a program and associate states which arise in its execution with entities in the domain.
% as an algorithm which solves the equations which govern it. Values, states, and transitions in the execution of the algorithm correspond to entities in the domain.
% This execution generally follows the causal direction of the domain in the sense that if $a$ causes $b$, $b$ is computed from $a$ in simulation.
% Problems of inference, on the other hand, are typically anti-causal: having observed the result of the simulation we wish to infer the causes.



% WTP: What are likelihood functions, why are they use useful, and why are they intractable
% The Bayesian approach to inference is to first quantify all uncertainty with probability distributions, and as a result uniquely specify the posterior distribution given observed values.
% % Bayesian inference is a principled framework for inferring probable causes of observed values, but relies on terms which are often intractable.
% Most algorithms which draw samples from posterior distributions rely on
% % Bayes theorem dictates that the posterior distribution over latent variables given observations is is proportional to the product of the likelihood function and prior.
% the likelihood function, which quantifies the extent to which values of latent variables are consistent with observations.
% Simulation models explicitly represent the processes which generate data, but leave the likelihood functions implicit. 
% The likelihood  difficult to derive from a simulation model and is often intractable to evaluate.
% This can occur, for example, when non-latent variables are unobserved, since they must be margainalized out, or when transformed densities are conditioned.
% Simulation based models can apply arbitrary, non-injective transformations to their input, and hence induce intractable likelihoods for any or all of these reasons.

% Morever, approximate inference algorithm 

% % A less explored cause of intractability occurs when we condition on propositions that are not observations of data.
% For example, if $X$ and $Y$ are normally distributed random variables, then conditioning on $X = Y$ does not permit a density function, let alone a tractable one.
% Conditioning on inequalities such $X > 4$, transformations such $X^2  = 0$, and logical formulas such as  $X = 3 \lor X = 5$ falls outside the domain of virtually all conditional sampling algorithms.
% % As a consequence, conditioning in practice is significantly more limited than its theoretical counterpart.

% The value of probabilistic programming systems hinges on how easily a practitioner can encode domain knowledge into a model. Existing probabilistic programming systems support two main mechanisms for encoding knowledge: implicitly in the generative model, and explicitly by conditioning on observations. There are many contexts, however, for which neither of these two mechanisms are sufficient to encode the knowledge that practitioners have about a process.

% WTP: Implications of the Problem


% WTP: Non-obvious benefits of solving the problem:  Prior conditioning.
% Declarative knowledge has the potential to serve as the bridge between classical parametric models, and recent trend towards nonparameric or highly parameterized families such as deep neural networks.
% For example, inverse graphics attempts to infer the three dimensional scene (geometry, lights, camera, etc) which caused an observed image.
% A Bayesian formulation of the problem requires a prior distributions over scenes.
% Simple parametric stand little chance of capturing the complexity of real world scenes.

% Outline: Non-observational predicates induce intractable likelihoods
% and are largely unsupported by current methods of inference
Several effective sampling  \citep{andrieu2003introduction} and variational  \citep{jordan1999introduction, ranganath2014black} approaches to inference require only a black-box likelihood function, i.e., one evaluable on arbitrary input.
The likelhood function quantifies the extent to which values of latent variables are consistent with observations. 
However, most models conditioned on most predicates have likelihood functions that are intractable to compute or unknown.
For example, conditioning random variables that are deterministic transformations of other random variables (e.g., the presence of hypoglycemia in the example above, or the mean of a collection of variables) often results in likelihoods that are normalized by intractable integrals.	
% For example, given three variables, it is possible to condition on the sum
% of the variables being positive; this sum is never an explicit random variable.
In other cases, the likelihood function is implicit to a generative process, rather than explicitly specified, and hence unavailable even when the condition is a conventional observation.

In this paper we present predicate exchange:
a likelihood-free method to sample from distributions conditioned on predicates from a broad class.
It is composed of two parts:
\begin{enumerate}
\item \textbf{Predicate Relaxation} transforms a probabilistic model such that predicates it is conditioned on take values in the unit interval $[0, 1]$ rather than $\{0, 1\}$.
\item  \textbf{Replica Exchange} simulates several Markov chains of models conditioned on predicates relaxed to different strengths, and in doing so is able to draw exact samples from the unrelaxed model. 
\end{enumerate}

Predicate relaxation meets two desiderata.
First, the value in $[0, 1]$ that a relaxed predicate takes denotes the degree to which it is satisfied.
In other words, a soft predicate quantifies the extent to which values of latent variables are consistent with the predicate.
This allows it to serve a role similar to a likelihood function, and opens up the use of likelihood-based inference procedures for a form of approximate posterior inference.
Second, relaxed predicates form a complete Boolean algebra, composed of conjunction, disjunction and negation.
This is crucial because domain knowledge often has a composite Boolean structure.
Continuing the previous example, we may know that a person does \emph{not} have hypoglycemia, or that they have hypoglycemia \emph{or} hyperglycemia, or \emph{neither}.
% Few likelihood-based likelihood-free approaches to inference offer effective means to condition non-trivial models on compound predicates.

% This degree to which a is is determined by a notion of distance.
% In contrast to most distance based inference methods (notably Approximate Bayesian Computation \cite{beaumont2002approximate}), we develop a form of replica exchange Markov Chain Monte Carlo \cite{earl2005parallel} to target inference that is exact in convergence of the chain.
% Predicate relaxation is modulated by temperature such that at zero temperature the relaxed predicate mirrors its hard counter-part, while at maximal temperatures, it is virtually always satisfied.
% Predicate Exchange simulates several Markov chains in parallel at different temperatures.

Predicate exchange is a response to probabilistic programming languages, which have vastly expanded the class of unconditional probabilistic models that can be expressed, but still largely restrict the kinds of predicates that can be practically conditioned on.
Rather than introduce a new language or modeling formalism, we mirror   \cite{wingate2011lightweight} and provide a light-weight implementation that performs inference by modulating the execution of stochastic simulation based model.
This means predicate exchange is easily incorporated into most frameworks. 

Our approach comes with certain limitations.
Predicates which indicate sets of zero measure -- typically due to equality conditions on continuous variables -- are problematic because they result in zero acceptance ratios.
In these cases predicate exchange must sample at a minimum temperature strictly greater than zero.
Predicate exchange is also sensitive to the choice of distance metric.
Moreover, to evaluate a soft predicate on models whose control-flow depends on a random variable, can in some cases itself be a	 hard problem.
% Nevertheless predicate exchange 

In summary we address the problem of conditioning probabilistic models on predicates as a means to express declarative knowledge.
In detail, we:

\begin{enumerate}
	\item Formalize simulation based probabilistic models in measure theoretic probability, and conditioning as the imposition of constraints expressed as predicates (Section \ref{simmodels}).
	\item Motivate predicate relaxation (Section \ref{predexchange}), and provide softened versions of primitive Boolean functions. 
	\item Provide a light-weight implementation of predicate exchange (Section \ref{implement}) through nonstandard execution of a simulation based model.
	\item Evaluate our approach on representative examples, and demonstrate case studies including enriching medical models with limited data.
\end{enumerate}


% WTP: Contribution: inference algorithm that supports conditioning on a wider class of propositions
% In this paper we present an algorithm that draws samples from generative models that have been conditioned on predicates belonging to a more general class than observation of data.
% Predicates, when used as black boxes, provide only sparse information -- the constraint is satisfied or it is not -- and the subset of satisfying constraints is typically vanishingly small.
% Our objective is to support conditioning on predicates on spaces for which a natural metric can be defined.
% A metric provides more information a measure of the degree of satisfaction, and allows us.

% WTP: Paper summary
% In summary we address the problem of conditioning on declarative knowledge.
% In more detail:
% \begin{itemize}
% \item We formalize simulation models in measure-theoretic probability as random variables defined on a shared probability space (section X), and define conditioning as a concentration of measure.
% \item We describe our approach to inference, which softens the hard constraints to admit tractable inference in a broader set of scenarios.
% \item  We demonstrate our approach on a number of examples, with experiments on toy data and experiments on medical models by enriching them with declarative knowledge to learn from limited data.
% \end{itemize}