\section{Predicate Exchange}
To condition a model $\cM$ on a predicate $Y$ we develop Predicate Exchange, a likelihood-free inference procedure.  It is composed of two parts:
\begin{enumerate}
\item \textbf{Predicate Relaxation} transforms $Y$ into a relaxed predicate $U_Y$ which takes values in the unit interval $[0, 1]$ rather than $\{0, 1\}$.
$U_Y$ is 1 iff $Y$ is 1, but otherwise takes nonzero values denoting the degree to which $Y$ is satisfied.
% The relaxation is parameterized by a temperature.
% Predicate relaxation allows us to apply likelihood based MCMC inference procedures.
\item  \textbf{Replica Exchange} is a Markov Chain Monte Carlo proecdure that exploits temperature. The degree to which $U_Y$ approximates $Y$ is modulated by a temperature parameter $\alpha$, where as $\alpha$ trades off between accuracy and ease of inference.  By simulating several replicas of $U_Y$ at different temperatures, replica exchange is able to draw exact samples from model condition on $Y$. 
\end{enumerate}

\subsection{Predicate Relaxation}

There are three desiderata which govern how the relaxed predicate $U_Y$ approximates $Y$.  First, $U_Y$ should have a temperature parameter $\alpha$ that controls the fidelity
of the approximation. In particular, $U_Y$ should converge to $Y$ as $\alpha \to 0$, and to a flat surface as $\alpha \to \infty$. Second, the fidelity of the approximation should vary monotonically with temperature, parameterizing a tradeoff between accuracy and ease of inference. Third, we must preserve consistency with $Y$. That is $Y(\omega) = 1$ iff $U_Y(\omega) = 1$ at all temperatures.  


% The family of approximations of the predicate $Y$ is parameterized through a temperature $\alpha$ that controls the smoothness of the approximation. In particular, $U_Y$ with $\alpha \to 0$ converges to $Y$ itself while increasing values of $\alpha$ yield smoother approximations eventually giving a flat surface when $\alpha \to \infty$. Moreover, the set of conditional samples $C(Y) = \{ \omega \in \Omega \text{ } | \text{ } Y(\omega) = 1 \}$ are assigned a value of $1$ in $U_Y$ for all temperatures. 

% To construct a $U_Y$ with such properties, we let $Y$ be the following predicate $a=b$ for standard Gaussians $a, b \sim \mathcal{N}(0, 1)$. We choose a distance
% $\rho(a, b)$ to indicate how close our sample is to $C(Y)$. To meet the desiderata
% of having $C(Y)$ be $1$ over the constraint set and to ensure the constraint becomes
% smoother with large $\alpha$, we use a function $k : [0, \infty] \to [0, 1]$ parameterized by $\alpha$ to wrap the distance $\rho(a, b)$. A simple choice for such a function is $k(d; \alpha) = e^{-d / \alpha}$ that provides the desired properties to $U_Y$ (see Appendix). The formal definition of $U_Y$ is as follows.

\begin{definition}
The function $U_Y : \Omega \to [0, 1]$ parameterized by $\alpha \in [0, \infty)$ is a relaxation of a $Y: \Omega \to \{0, 1\}$ if:
\begin{enumerate}[label=(\roman*)]
	\label{def:temp}
	\item For all $\omega \in \Omega$, $\lim_{\alpha \to 0}U_Y(\omega; \alpha) = Y(\omega)$.
	\item For all $\omega \in \Omega$, $\lim_{\alpha \to \infty}U_Y(\omega; \alpha) = 1$.

    \item For all $\alpha$, $U_Y(\omega; \alpha) = 1$ iff $Y(\omega) = 1$.
    \item The entropy $H(U_Y(\omega; \alpha))$ (which characterizes the fidelity of the approximation ) is an increasing function of $\alpha$.\footnote
    {By compactness, it is integrable for all $\alpha$, when $\Omega$ has finite dimension}
\end{enumerate}
\end{definition}


The construction of $U_Y$ from $Y$ (Section X) substitutes primitive predicates (equality, inequalities and logical operators) in the model with soft predicates.
Soft predicates rely on a notion of distance, such that the degree to which a predicate is satisfied is a measure of closeness in a metric space. 
For example if $X_1$ and $X_2$ are random variables, and $\tilde{=}$ is the soft equality, then $X_1 = X_2$ is defined as $U_Y = e^{-\rho(X_1, X_2) / \alpha}$ where $\rho$ is a distance function on the realization space of $X_1$ and $X_2$.

% We derive $U_Y$ from $Y$ semi-automatically. 
% Recall that a probabilistic model $\mathcal{M}$ is a collection of random variables on a shared probability space, and that a predicate $Y \in \mathcal{M}$ is generally a composition of these variables.
% We derive $U_Y$ from $Y$ by replacing all predicates (Boolean valued functions) in $Y$ with corresponding relaxations defined on $\mathbb{R}$.
% In programming language terminology this is a nonstandard execution of $Y$ and can be implemented by a source to source transformation of the code which comprises $Y$.
Soft  predicates take the form $k_\alpha(\rho(a, b); \alpha)$, 
where $\rho$ is a distance metric.
The distance from a point to a set, i.e.:
$$
\rho(x, A) = \inf \left\{\rho(x, a) \mid a \in A\right\}
$$

Notably, the distance from a real value $x$ to an interval $A = [a, b]$ is:
\begin{equation}
\rho(x, [a, b]) =
\begin{cases}
  a - b, & \text{ if } x < a\\
  x - b, & \text{ if } x < b\\
  0,              & \text{otherwise}
\end{cases}
\end{equation}

  % \begin{center}
  % \begin{tabular}{ c |  c | c }
  %   \hline		
  %   $x \soft{=} y$ & $x \soft{>} y$ & $x \soft{<} y$  \\
  %   $k_\alpha(\rho(x, y))$ & $k_\alpha(\rho(x, [y, \infty]))$ & $k_\alpha(\rho(x, [-\infty, y]))$ \\
  %   \hline  
  % \end{tabular}
  % \end{center}


\begin{figure}
  \begin{align*}
x \soft{=} y &= k_\alpha(\rho(x, y))\\
x \soft{>} y &= k_\alpha(\rho(x, [y, \infty]))\\
% x \soft{<} y &= k_\alpha(\rho(x, [-\infty, y]))\\
x \soft{<} y &= k_\alpha(\rho(y, [-\infty, x]))\\
a \soft{\land} b &= \max(a, b)\\
a \soft{\lor} b &= \min(a, b)
  \end{align*}
\caption{Soft Primitive Predicates}
\end{figure}

\subsection{Kernels}
Kernels, also called covariance functions Write about kernels

\paragraph{Negation}
Negation requires special treatment.
Continuous logics typically define the negation of $a \in [0, 1]$ as $1 - a$.
Unfortunately, this violates criteria (iii): at temperatures other than $0$ or $1$, scenarios which satisfy $\neg Y$ will have 
Figure X visualizes the problem using the example $X \soft{>} 0$ and its negation.

The problem arises because the consistency requirements are one-sided; they preserve consistency with $Y$ at 1 but not at 0.
To overcome this challenge, predicate relaxation keeps two counterparts of relaxation: $\tilde{a}$ defined above, and $\tilde{a}'$ defined the same way but That is, $U_Y$ is a two-sided relaxation of $Y$ if it returns a pair $(b_0, b_1)$, where $b_0, b_0 \in [), 1]$.
$b_1$ preserves consistency with $Y$ on $1$, i.e. introduces approximates on $0$.
In contrast, $b_0$ preserves consistency with $Y$ on $0$, and introduces approximations on $1$.

\begin{definition}
The function $U_Y : \Omega \to [0, 1]^2$ parameterized by $\alpha \in [0, \infty)$ is a two-sided relaxation of a $Y: \Omega \to \{0, 1\}$ if:
\begin{enumerate}[label=(\roman*)]
	\label{def:temp}
	\item For all $\omega \in \Omega$, $\lim_{\alpha \to 0}U_Y(\omega; \alpha) = (\neg Y(\omega), Y(\omega))$.
	\item For all $\omega \in \Omega$, $\lim_{\alpha \to \infty}U_Y(\omega; \alpha) = (0, 1)$.

    \item For all $\alpha$, $U_Y(\omega; \alpha) = 1$ iff $Y(\omega) = 1$.
    \item The entropy $H(U_Y(\omega; \alpha))$ (which characterizes the fidelity of the approximation ) is an increasing function of $\alpha$.\footnote
    {By compactness, it is integrable for all $\alpha$, when $\Omega$ has finite dimension}
\end{enumerate}
\end{definition}


\begin{figure}
\begin{align*}
x \dsoft{=} y &= (\text{if } x = y  \text{ then } \alpha \text{ else } 1, k_\alpha(\rho(x, y)))\\
x \dsoft{>} y &= (k_\alpha(\rho(x, [-\infty, y])), k_\alpha(\rho(x, [y, \infty])))\\
x \dsoft{<} y &= (k_\alpha(\rho(y, [x, \infty])), k_\alpha(\rho(y, [-\infty, x])))\\
(a_0, a_1) \dsoft{\land} (b_0, b_1) &= (a_0 \soft{\land} b_0, a_1 \soft{\land} b_1)\\
(a_0, a_1) \dsoft{\lor} (b_0, b_1) &= (a_0 \soft{\lor} b_0, a_1 \soft{\lor} b_1)\\
\dsoft{\neg}(a_0, a_1) &= (a_1, a_0)
\end{align*}
\caption{Soft Primitive Predicates with Two-Sided Error}
\end{figure}

% \begin{center}
% \begin{tabular}{ l | c | r }
%   % \hline		
%   $(a_0, a_1) \soft{\land} (b_0, b_1)$ & $(a_0, a_1) \soft{\lor} (b_0, b_1)$ & $\neg(a_0, a_1)$ \\
%   $(a_0, a_1) \soft{\land} (b_0, b_1)$ & $(a_0, a_1) \soft{\lor} (b_0, b_1)$ & $\neg(a_0, a_1)$ \\
%   % \hline  
% \end{tabular}
% \end{center}



\subsection{Approximate Markov Chain Monte Carlo}
A relaxed predicate can act as approximate likelihood in likelihood based inference methods such as Markov Chain Monte Carlo.
MCMC algorithms require a function $f$ that is proportional to the the target density.
In Bayesian inference this is the posterior, dictated by Bayes' theorem as the product of the likelihood and the prior.
Approximate inference using relaxed predicates takes a similar form.

Let $\cM$ be a model, $Y$ be a predicate that conditions $\cM$, and $U_Y$ be a relaxation of $Y$.
Random variables in $\cM$ may be exogenous or endogenous in the sense that
given values for exogenous variables, the values of endogenous are determined.
For example $X = \mathcal{N}(0,1)$ is exogenous while $Y = X^2$ is endogenous.
Inference need only take place on exogenous random variables.
Both $Y$ and $U_Y$ are endogenous random variables, mapping from the sample space $\Omega$.
For convenience, let $u$ denote a relaxed predicate that takes as input values of exogenouos random variables in the model, rather than elements of the sample space.
That is, if $X_1(\omega), \dots, X_n(\omega) = (x_1, \dots, x_n)$, then $u(x_1, \dots, x_n) = U_Y(\omega)$.
Assuming a prior $p$, the approximate posterior $f$ is the product of these terms:
\begin{equation}
f(m) = p(m) \cdot u(m)
\end{equation}
At zero temperature $f$ is exactly the posterior, since parameter values which violate the condition are given zero weight.

As a complete let $\cM = (X, Y, Z)$ be a model where $X, Y \sim \textrm{Normal}(0, 1)$, $Z = X + Y$ and $\cM$ is conditioned on $Z = 0$.
$X$ and $Y$ are exogenous, whereas $Z$ is endogenous.
The approximate posterior is then defined as:

$$
f(x, y) = \mathcal{N}_{0,1}(x) \cdot \mathcal{N}_{0,1}(y) \cdot k(x + y, 0) 
$$

The approximate posterior is shown in figure X.

\subsection{Replica Exchange}

The temperature parameter trades off between tractability of inference and the fidelity of the approximation.
Too high and $U_Y$ will diverge too greatly from $Y$; too low and convergence will be slow.
% Several temperatre methods for controlling temperature exist such as simulated annealing \citep{kirkpatrick1983optimization} and Adiabatic Monte Carlo \citep{betancourt2014adiabatic}.
Replica exchange (also known as parallel tempering) \citep{swendsen1986replica} offers a means to effectively sample from the zero temperature chain.

In a replica exchange, we simulate $M$ replicas at different temperatures, and periodically swap the temperatures of chains according to a predefined schedule.
Replica exchange uses a Metroplis-Hastings update to swap between changes while preserving the target distribution.
With two independent parallel chains.
The swap is accepted with probability $\min{1, A}$ where:

To keep things simple, let’s just suppose that we have two (independent, parallel) chains, one with target $f(x)$ and the other with target $g(y)$. We can consider these chains to be evolving together, with joint target $\pi(x,y)=f(x)g(y)$. The updates chosen to update the within-chain states will obviously preserve this joint target. Now we consider how to swap states between the two chains without destroying the target. We simply propose a swap of x and y. That is, we propose to move from $(x,y)$ to $(x^\star,y^\star)$, where $x^\star=y$ and $y^\star=x$.

$$
A = \frac{\pi(x^\star,y^\star)}{\pi(x,y)} = \frac{\pi(y,x)}{\pi(x,y)} = \frac{f(y)g(x)}{f(x)g(y)}.
$$


Replica exchange has a number of hyperparameters: the number of parallel chains $M$, the corresponding temperatures, the schedule for swapping.
Following \cite{} we choose temperatures we choose temperatures logarithmiatcally spaced between $0$ and an upper bound, and swap adjacent chains $X_1$ with $X_2$, $X_2$ with $X_3$, etc periodically.


% This scenario closely resembles the reparameterization trick \citep{Kingma:2014, rezende2014stochastic} where one resorts to include all the uncertainty of a random variable $z$ in a simple, easy-to-sample, parameter-free noise source such as $\epsilon \sim \mathcal{N}(\mathbf{0}, I)$. The actual random variable $z$ is then obtained through a parametric transformation of the noise, $z = f(\epsilon; \theta)$. Both methods separate the 
% uncertainty of a random variable from the deterministic transformation that results in a complex density. However, in the reparameterization trick the noise source is constant and controlled while the parametric transformation is meant to infer the structure of the resulting random variable. Conversely, our forward model -- deterministic transformation -- is constant and controlled, hence we simply transfer our inference problem to a much simpler space of $\Omega$.

Predicate Exchange has a connection to approximate Bayesian computation (ABC) methods~\citep{beaumont2002approximate} in that ABC methods 
sample using a distance function to induce a data likelihood. Our method differs in that conditionals can be any predicate not just
one for an observed random variable.
% Finally for inference, with the soft predicates we define, we
% can use modern likelihood-free variational inference algorithms
% that construct an approximation to a conditional with only samples
% from the joint and samples from the conditional approximation~\citep{tran2017hierarchical}.

