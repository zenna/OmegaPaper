\section{Implementation}\label{implement}
% \begin{exprogram}
% \begin{algorithmic}
% \State Hello
% \end{algorithmic}
% \caption{A mega algorithm}
% \end{exprogram} 

% Our approach to inference is not black-box.
% It requires a transformation of the model.
% This can be realized in a number of ways.
% To formalize this we introduce a very simple language for describing probabilistic models.
% Following this, we demonstrate how these principle can be incorporated into existing languages.


% \subsection{A Minimal Language}{\label{minilang}}


% \begin{figure}[t]
% 	\begin{align*}
% 		\text { model term }  &  & \enspace m ::=               & e ; \cond f \\
% 		\text { standard term }  &  & \enspace e ::=               & e ; e \mid v \sim f\\
% 		\text { standard term }  &  & \enspace f ::=               & p \mid f \textrm{ bop }f \mid\textrm{ op } f \mid \\
% 		\text { standard term }  &  & \enspace f ::=               & \text{ if } t_1 \text{ then } t_2 \text{ else } t_3 \\
% 		\text { binary op }      &  & \enspace \textrm{bop} ::=    & + \mid - \mid / \mid * \mid \land \mid \lor \mid > \mid < \mid \\
% 		\text { unary op }       &  & \enspace \textrm{uop} ::=    & \lnot                                                          \\
% 		\text { primitive dist } &  & \enspace p ::= \bern(f) \mid & \unif(f, f) \mid N(f, f) \mid                                  \\
% 	\end{align*}
% 	\caption{Abstract Syntax}
% 	\label{syntax}
% \end{figure}

% Figure \ref{Syntax} describes the abstract syntax of our language.
% The language closey resembles statistical notation.
% One difference is that conditions are stated at the end of each model in a single statement $\cond$.

% Here is an example.

% \begin{align*}
% 	x \sim   & \unif(0, 1)           \\
% 	y \sim   & \unif(0, 1)           \\
% 	\cond \; & (x = y) \land (x > 3) \\
% \end{align*}

% \subsubsection{Semantics}\label{semantics}
% \newcommand{\sem}[1]{\llbracket #1 \rrbracket}
% Here we define a semantics denotationally.
% The denotation $\sem{t}$ of a term $t$ is a value in a semantic domain corresponding to an \omegalang{} type, such as a Boolean, real number, or random variable.
% Primitive 


% \subsection{Syntactic Predicate Relaxation}

% The transformation from the original model to a relaxed model is straight forward.
% Algorithm substitutes X accepts as input the abstract syntax

% \begin{figure}[t]
% 	\begin{align*}
% 		\text { model term }  &  & \enspace m ::=               & e ; \cond f \\
% 		\text { standard term }  &  & \enspace e ::=               & e ; e \mid v \sim f\\
% 		\text { standard term }  &  & \enspace f ::=               & p \mid f \textrm{ bop }f \mid\textrm{ op } f \mid \\
% 		\text { standard term }  &  & \enspace f ::=               & \text{ if } t_1 \text{ then } t_2 \text{ else } t_3 \\
% 		\text { binary op }      &  & \enspace \textrm{bop} ::=    & + \mid - \mid / \mid * \mid \land \mid \lor \mid > \mid < \mid \\
% 		\text { unary op }       &  & \enspace \textrm{uop} ::=    & \lnot                                                          \\
% 		\text { primitive dist } &  & \enspace p ::= \bern(f) \mid & \unif(f, f) \mid N(f, f) \mid                                  \\
% 	\end{align*}
% 	\caption{Abstract Syntax}
% 	\label{syntax}
% \end{figure}

% \begin{align*}
% 	x \sim \unif(0, 1)              \\
% 	y \sim \unif(0, 1)              \\
% 	ll \sim x =_s y \land_s x >_s 3 \\
% \end{align*}

% \subsection{A Lightweight Implementation}\label{rng}

In this section we describe an implementation of predicate exchange.
Our approach resembles \citep{wingate2011lightweight, milch20071} as a language independent layer that can sit on top of existing programming languages and modeling formalisms.
Our objective is twofold: (i) to compute the prior term $p$, approximate likelihood term $\softv{\lk}$, and approximate posterior term $f$ (Equation \ref{approxposterior}) from an arbitrary simulator $\pi$, and (ii) to perform replica exchange MCMC to sample from the posterior.

We define a simulator $\pi$ as a program composed of deterministic and stochastic procedures, but where all randomness comes from a set of known random primitives.
Primitives correspond to primitive parametric distribution families, such as the uniform or normal distribution.
Let $\mathcal{T}$ be a set of primitive types.
Each type $\tau \in \mathcal{T}$ must support (i) evaluation of the conditional density $p_\tau(x \mid \theta_1, ..., \theta_n)$, and (ii) sampling from the distribution.
Concretely, $\pi$ is any nullary program that contains the statements:

\begin{enumerate}
  \item $\textrm{rand}(n, \tau, \theta_1, ...,\theta_n)$ returns a random sample from $p_\tau(\; \cdot \mid \theta_1, ..., \theta_n)$.  $n$ is a unique name described below.
  \item $\cond(y)$ conditions $\pi$.  It throws an error if $y \in \{0, 1\}$ is 0, and otherwise allows the execution to resume.
\end{enumerate}

Example Programs 1 and 2 illustrate conditioned models.

Names (e.g. $n_x$) passed to $\textrm{rand}$ are not the same as variable names (e.g. $x$) in the host programming language.
If two distinct names are used, the samples output from $\textrm{rand}$ will be independent or conditionally independent.
Care must be taken when a program has loops to avoid inadvertently reusing the same name.
A simple solution is to append the the loop counter to the name.



\subsection{Tracked Soft Execution}
Predicate exchange relies on $\textrm{softexecute}$
(Algorithm \ref{alg:softexecute}), which formalizes the soft execution of a program $\pi$  at temperature $\alpha$ in the context of dictionary $\mathbb{D}$.
$\mathbb{D}$ is a mutable mapping from a name to a value.
In the context of a particular dictionary, the simulation of a program is deterministic.
This allows the simulation of $\pi$ to be modulated by controlling the elements of $\mathbb{D}$.


$\textrm{softexecute}$ computes the prior term $p$ as the product of random choices in the program. 
That is, let $\pi_{k \mid x_1, ..., x_{k-1}}$ be the k'th random primitive encountered while executing $\pi$, $x_k$ be the value it takes, and $x$ denote the set of all values of all random primitives constructed in the simulation of $\pi$, $p(x)$ is then the product:
\begin{equation}\label{productprob}
p(x) = \prod_{k=1}^K p_\tau(x_k \mid \theta_1,..., \theta_n )
\end{equation}
The parameters $\theta_1,..,\theta_n$ may be fixed values or depend on values of other random primitives in $\pi$.

% \begin{exprogram}[tb]
% \caption{}
% \label{prog:ex1}
% \begin{algorithmic}
% \STATE $x = \textrm{rand}(n_x, \mathcal{N}, 0, 1)$
% \STATE $y = \textrm{rand}(n_y, \mathcal{N}, 0, 1)$
% \STATE $\cond(x > y)$
% \STATE {\bfseries Return:} $(x, y)$
% \end{algorithmic}
% \end{exprogram}


\begin{figure}[tb]
  \centering
  \begin{subfigure}[t]{4cm}
    \vskip 0pt
      \begin{algorithmic}
      \STATE \textbf{Example Program 1}
      \STATE 1. $x = \textrm{rand}(n_x, \mathcal{N}, 0, 1)$
      \STATE 2. $y = \textrm{rand}(n_y, \mathcal{N}, 0, 1)$
      \STATE 3. $\cond(x < y)$
      \STATE 4. {\bfseries Return:} $(x, y)$
      \end{algorithmic}
  \end{subfigure}%
  \hfill
  \begin{subfigure}[t]{4cm}
    \vskip 0pt
      \begin{algorithmic}
      \STATE \textbf{Example Program 2}
      \STATE $x = \textrm{rand}(n_x, \mathcal{N}, 0, 1)$
      \IF {$x < 0$}
      \STATE $\cond(x = -100)$
      \ENDIF
      \STATE {\bfseries Return:} $x$
      \end{algorithmic}
      % \end{exprogram}
  \end{subfigure}
\end{figure}

\begin{figure}
\begin{center}
  \begin{tabular}{ |c|c|c|c| } 
   \hline
   L & $\mathbb{D}$ &  $p_\mathbb{D}$ & $\log(\softv{\ell}_\mathbb{D})$ \\
   \hline
   $1$ & $\emptyset$ & $1$ & $0$ \\ 
   $2$ & $ n_x \mapsto 0.9$ & $p_\mathcal{N}(0.9) = 0.3$ & $0$ \\ 
   $3$ &  $n_x, n_y \mapsto 0.9, 0.2$ & $0.3 p_\mathcal{N}(0.2) = 0.1$ & $0$ \\
   $4$ & $n_x, n_y \mapsto 0.9, 0.2$ & $0.1$ & $-700$ \\ 
   \hline
  \end{tabular}
\end{center}
\caption{softexecute on Program 1.  Each row shows $\mathbb{D}$,  $p_\mathbb{D}$ and $\log(\softv{\ell}_\mathbb{D})$ just prior to executing line L.  $p_\mathcal{N}$ denotes standard normal pdf.  Final $\log(\softv{\ell}_\mathbb{D})$ is $0.9 \soft{<} 0.2$, which is $-700$ at $\alpha = 0.001$.}
\label{table:sofex}
\end{figure}


$\textrm{softexecute}$ executes $\pi$ but within a context where (i) variables $\lk_\mathbb{D}$ and $p_\mathbb{D}$ accumulate prior and approximate posterior values, and (ii) the following operators are redefined:

\begin{enumerate}
  \item $\textrm{rand}(\tau, n, \theta_1, ...\theta_n)$ returns $\mathbb{D}(n)$ if $n$ is a key in $\mathbb{D}$ (denoted $n \in \mathbb{D}$), and updates $p_\mathbb{D}$ according to Equation \ref{productprob}. If $n \notin \mathbb{D}$, the distribution is sampled from and $\mathbb{D}(n)$ is updated with this value.  
  \item $a \text{ op } b$ and $\textrm{op } a$ for $\textrm{op} \in \{>, <, =, \land, \lor, \neg\}$ are replaced with soft versions $\soft{\textrm{ op }} \in \{\soft{>}, \soft{<}, \soft{=}, \soft{\land}, \soft{\lor}, \soft{\neg}\}$.
  \item $\cond(y)$ updates $\softv{\lk}_\mathbb{D}$ with $\softv{\lk}_\mathbb{D} \soft{\land} y$. $y$ will be a soft Boolean rather than a Boolean due to substitution of primitives with soft primitives as per the previous step.
\end{enumerate}

$\textrm{softexecute}$ returns a value for the approximate posterior as a function of $\mathbb{D}$.  Figure \ref{table:sofex} vizualises its progression.

\paragraph{Control Flow}
Programs often have control flow.
If a branch condition depends on a soft Boolean, softexecute follows the path taken by the unrelaxed program.  That is, if $a$ is a soft Boolean, \textbf{if} $a$ \textbf{then} $b$ evaluates $b$ iff $a = 1$.
One consequence of this is that there may be unexplored paths which would, if explored, produce values that are closer to or within the satisfying set.
% $\textrm{softexecute}$ is ignorant of these other possibilities.
For illustration, if $x = -0.01$ in Example Program 2,
 the branch condition succeeds and \textrm{softexecute} will evaluate $x \soft{=} -100$. However, with only a small change to $x$, the branch condition fails, and the path taken has has no conditions.
 $\softv{\ell}$ therefore over approximates the change required to satisfy $\ell$.
%  This is significantly larger than if the true branch were taken.
% These may cause $\textrm{softexecute}$ to return a value that is significantly less than $\soft{\lk}_{\inf}$ does.

% These may cause $\textrm{softexecute}$ to return a value that is significantly less than $\soft{\lk}_{\inf}$.


% \begin{exprogram}[tb]
% \caption{}
% \label{prog:ex2}
% \begin{algorithmic}
% \STATE $x = \textrm{rand}(n_x, \mathcal{N}, 0, 1)$
% \IF {$x > 0$}
% \STATE $\cond(x = 1)$
% \ELSE
% \STATE $\cond(x = -100)$
% \ENDIF
% \STATE {\bfseries Return:} $x$
% \end{algorithmic}
% \end{exprogram}



\begin{algorithm}[tb]
  \caption{Soft Execution: $\textrm{softexecute}(\pi, \alpha, \mathbb{D})$}
  \label{alg:softexecute}
\begin{algorithmic}
\STATE {\bfseries Input:} program $\pi$, temperature $\alpha$, dictionary $\mathbb{D}$
\STATE Initialize $\softv{\lk}_\mathbb{D} = 1, p_\mathbb{D} = 1$
\STATE Simulate $\pi$ with following subroutines redefined as:   
\ALOOP {$\textrm{rand}(n, \tau, \theta_1, ..., \theta_n)$}
   \IF{$n \in \mathbb{D}$}
   \STATE $x \deqq \mathbb{D}(n)$
 \ELSE
   \STATE $x \deqq $ sample from $p_\tau(x \mid \theta_1, ..., \theta_n)$
   \STATE Update dictionary: $\mathbb{D}(n) \deq x$
 \ENDIF
 \STATE $p_\mathbb{D} \deq p_\mathbb{D} \cdot p_\tau(x \mid \theta_1, ..., \theta_m)$
 \STATE Return from subroutine: $x$
\ENDALOOP
\STATE
\ALOOP {$\cond(y)$}
  \STATE $\softv{\lk}_\mathbb{D} \deq \softv{\lk}_\mathbb{D} \soft{\land} y$
\ENDALOOP
\STATE
\ALOOP {$\textrm{op}(x, \dots)$ for $\textrm{op} \in \{>, <, =, \land, \lor, \neg\}$}
  \STATE Return from subroutine: $\soft{\textrm{op}}(x, \dots)$ 
\ENDALOOP
\STATE
% \IF{$s = \textrm{rand}(\tau, n, \theta_1, ..., \theta_n)$}
%  \IF{$n \in \mathbb{D}$}
%    \STATE $x = \mathbb{D}(n)$
%  \ELSE
%    \STATE $x = $ sample from $p_\tau(x \mid \theta_1, ..., \theta_n)$
%    \STATE Update dictionary: $\mathbb{D}(n) = x$
%  \ENDIF
%  \STATE $p_\mathbb{D} = p_\mathbb{D} \cdot p_\tau(x \mid \theta_1, ..., \theta_m)$
%  \ELSIF{$s = \cond(\lk')$}
%    \STATE $\lk_\mathbb{D} = \lk_\mathbb{D} \cdot \lk_\mathbb{D}'$
%  \ENDIF
\STATE {\bfseries Return:} $p_\mathbb{D} \cdot \softv{\lk}_\mathbb{D}$
%    \ENDFOR
%    \UNTIL{$noChange$ is $true$}
\end{algorithmic}
\end{algorithm}

\subsection{Replica Exchange}

$\textrm{predexchange}$ (Algorithm \ref{alg:predexchange}) performs replica exchange using $\textrm{softexecute}$ to compute approximate posterior values.
It takes as input an MCMC algorithm, which simulates a Markov Chain by manipulating elements of the $\mathbb{D}$.

% To illustrate, consider drawing two samples. 
% For example, consider $\textrm{softexecute}(\pi, \alpha, \mathbb{D})$ where $\pi$ is Example Program 1, $\alpha$ is 1 and $\mathbb{D}$ is empty.
% Lines 1 and 2 will draw two independent values $(v_x, v_y)$ from the standard normal distributions, and update (i) the prior term $p_\mathbb{D}$ with update $\mathbb{D}$ with these values such that $\mathbb{D}(n_x) \mapsto v_x$ and $\mathbb{D}(n_y) \mapsto v_y$.  $\textrm{cond}$ on line 3 will update the approximate likelihood term to $x \soft{>} y$.
% The returns approximate posterior will thus be


% Rep
% Each dictionary should contains all the information required to access values of variables of interest, either explicitly as values in the dictionary, or derivable with the simulator $\pi$. 



\begin{algorithm}[tb]
  \caption{Predicate Exchange: $\textrm{predexchange}$}
  \label{alg:predexchange}
\begin{algorithmic}
\STATE {\bfseries Input:} program $\pi$, temperatures $\alpha_1, ...,\alpha_m$, nsamples $n$
\STATE {\bfseries Input:} mcmc, nsamples between swaps $q$ 
\STATE Initialize $\mathcal{D} = $ empty collection of dictionarys
\STATE Initialize $\mathbb{D}^{\textrm{init}}_1,...,\mathbb{D}^{\textrm{init}}_m$ empty dictionarys
\STATE Define $f_{\alpha_i}(\mathbb{D}) = \textrm{softexecute}(\pi, \alpha_i, \mathbb{D})$
\REPEAT
  \FOR{$i=1$ {\bfseries to} $M$}
    \STATE { $\mathbb{D}_1,...,\mathbb{D}_q \deqq $ $q$ mcmc samples at temp $\alpha_i$}, from $\mathbb{D}^{\textrm{init}}_i$
    \STATE $\mathbb{D}^{\textrm{init}}_i \deqq \mathbb{D}_q$
    \FOR{$j=1$ {\bfseries to} $q$}
      \IF {$f_{\alpha_1}(\mathbb{D}_j) = 1$}
        \STATE append $\mathbb{D}_j$ to $\mathcal{D}$
      \ENDIF
    \ENDFOR
  \ENDFOR
  \FOR{$i = m$ {\bfseries down to} $2$}
    \STATE $j \deqq i - 1$
    \STATE $p \deqq {f_{\alpha_i}(\mathbb{D}_j)f_{\alpha_j}(\mathbb{D}_i)}/{f_{\alpha_i}(\mathbb{D}_i)f_{\alpha_j}(\mathbb{D}_j)}$
    \IF{$p >$ random sample in $[0, 1]$}
      \STATE swap $\alpha_i$ with $\alpha_j$
    \ENDIF
  \ENDFOR
\UNTIL{$\mathcal{D}$ has $n$ elements}
\STATE {\bfseries Return:} $\mathcal{D}$
\end{algorithmic}
\end{algorithm}
